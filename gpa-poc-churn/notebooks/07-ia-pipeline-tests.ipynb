{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "005c50df-c4c1-405e-93b5-10175356de1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install jupyter_contrib_nbextensions\n",
    "# !jupyter contrib nbextension install - user\n",
    "# from jedi import settings\n",
    "# settings.case_insensitive_completion = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67443260-a0bc-4605-b53c-be64ae15d16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install ai platform and kfp\n",
    "# USER_FLAG = \"--user\"\n",
    "# !pip3 install {USER_FLAG} google-cloud-aiplatform==1.3.0 --upgrade\n",
    "# !pip3 install {USER_FLAG} kfp --upgrade\n",
    "# !pip install google_cloud_pipeline_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88044735-902b-41ef-8f4c-2e01821eb9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kfp --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d591c5b2-2d78-4d10-9363-b4a3aff21951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud services enable compute.googleapis.com         \\\n",
    "#                        containerregistry.googleapis.com  \\\n",
    "#                        aiplatform.googleapis.com  \\\n",
    "#                        cloudbuild.googleapis.com \\\n",
    "#                        cloudfunctions.googleapis.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a19aaf51-d63d-4771-92f0-45c356bc586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import (Artifact,\n",
    "                        Dataset,\n",
    "                        Input,\n",
    "                        Model,\n",
    "                        Output,\n",
    "                        Metrics,\n",
    "                        ClassificationMetrics,\n",
    "                        component, \n",
    "                        OutputPath, \n",
    "                        InputPath)\n",
    "\n",
    "from kfp.v2 import compiler\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ab6367-523a-4b42-a5da-123405dc2bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_FLAG = \"--user\"\n",
    "#!gcloud auth login if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af458713-51b7-465f-be5d-e76d5c2d1de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpa-poc-001'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get projet name\n",
    "shell_output=!gcloud config get-value project 2> /dev/null\n",
    "PROJECT_ID=shell_output[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "412eb35a-3148-4af2-97e1-a31e1b7064b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://gpa-churn/artifacts/pipeline-vertexai/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set bucket name\n",
    "BUCKET_NAME=\"gs://gpa-churn/artifacts\"\n",
    "\n",
    "# Create bucket\n",
    "PIPELINE_ROOT = f\"{BUCKET_NAME}/pipeline-vertexai/\"\n",
    "PIPELINE_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0fe1b1b-fc92-442a-81cb-797b0c3adab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'southamerica-east1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REGION=\"southamerica-east1\"\n",
    "REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdc46021-ba2b-4fcd-8d49-f1af7ba62244",
   "metadata": {},
   "outputs": [],
   "source": [
    "requirement_list = [\n",
    "    \"pandas==1.3.5\",\n",
    "    \"xgboost==1.5\",\n",
    "    \"scikit-learn\",\n",
    "    \"pickle-mixin\",\n",
    "    \"numpy\",\n",
    "    \"jupyterlab==3.1.12\",\n",
    "    \"ipywidgets>=7.6\",\n",
    "    \"matplotlib==3.3.4\",\n",
    "    \"jupyter-dash\",\n",
    "    \"plotly==5.3.1\",\n",
    "    \"pytest==6.2.2\",\n",
    "    \"seaborn==0.11.1\",\n",
    "    \"glob2==0.7\",\n",
    "    \"SQLAlchemy==1.3.24\",\n",
    "    \"lightgbm==3.2.0\",\n",
    "    \"tabulate==0.8.9\",\n",
    "    \"shap==0.39.0\",\n",
    "    \"optuna==2.6.0\",\n",
    "    \"dython==0.6.4\",\n",
    "    \"minepy==1.2.5\",\n",
    "    \"pyarrow==3.0.0\",\n",
    "    \"kmodes==0.11.0\",\n",
    "    \"dash==1.19.0\",\n",
    "    \"dash-daq==0.5.0\",\n",
    "    \"nltk\",\n",
    "    \"unidecode\",\n",
    "    \"fsspec\",\n",
    "    \"gcsfs\",\n",
    "    \"joblib\",\n",
    "    \"great-expectations==0.13.17\",\n",
    "    \"google-cloud-storage\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20534a88-4c71-4959-a3d3-ebd434803ebd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Creating pipeline components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c05acf6-399b-4e8e-bd57-30a70e2904f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    #packages_to_install=requirement_list,\n",
    "    base_image=\"gcr.io/gpa-poc-001/churn-base-image-src-xgb@sha256:61db16ec13bba7d8023fff61329c6c28a7eb119f8f837fce4c09258776c16727\",\n",
    "    output_component_file=\"get_preprocessed_data.yaml\"\n",
    ")\n",
    "\n",
    "def get_preprocessed_data(\n",
    "    Xtrain_: Output[Dataset],\n",
    "    Xval_: Output[Dataset],\n",
    "    ytrain_: Output[Dataset],\n",
    "    yval_: Output[Dataset],\n",
    "    prefix:str='gs://gpa-churn/data/processed/input/'\n",
    "    ):\n",
    "    \n",
    "    import os\n",
    "    import gc\n",
    "    import sys\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from google.cloud import storage\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    df_train = pd.read_parquet('gs://gpa-churn/data/processed/train/dataset.parquet')\n",
    "    df_val = pd.read_parquet('gs://gpa-churn/data/processed/validation/dataset.parquet')\n",
    "    n_samples = int(len(df_train[df_train['target']==1]))\n",
    "    df_train_0 = df_train[df_train['target']==0].sample(n_samples)\n",
    "    df_train_1 = df_train[df_train['target']==1]#.sample(n_samples)\n",
    "    df_train = pd.concat([df_train_0, df_train_1], axis=0)\n",
    "    df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    target = 'target'\n",
    "    features = list(df_train.columns)\n",
    "    features = [i for i in features if i!=target]\n",
    "\n",
    "    Xtrain = df_train[features]\n",
    "    Xval = df_val[features]\n",
    "    ytrain = df_train[[target]]\n",
    "    yval = df_val[[target]]\n",
    "    \n",
    "    Xtrain.to_parquet(Xtrain_.path + '.parquet', index=False, compression='gzip')\n",
    "    Xval.to_parquet(Xval_.path + '.parquet', index=False, compression='gzip')\n",
    "    ytrain.to_parquet(ytrain_.path + '.parquet', index=False, compression='gzip')\n",
    "    yval.to_parquet(yval_.path + '.parquet', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfecf906-beaa-4195-a33e-984197f1d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    #packages_to_install=requirement_list,\n",
    "    base_image=\"gcr.io/gpa-poc-001/churn-base-image-src-xgb@sha256:61db16ec13bba7d8023fff61329c6c28a7eb119f8f837fce4c09258776c16727\",\n",
    "    output_component_file=\"train_model.yaml\"\n",
    ")\n",
    "\n",
    "def train_model(\n",
    "    Xtrain_: Input[Dataset],\n",
    "    Xval_: Input[Dataset],\n",
    "    ytrain_: Input[Dataset],\n",
    "    yval_: Input[Dataset],\n",
    "    model_: Output[Model]\n",
    "    ):\n",
    "    \n",
    "    import os\n",
    "    import sys\n",
    "    import pytz\n",
    "    import joblib\n",
    "    import pandas as pd\n",
    "    import xgboost as xgb\n",
    "    from datetime import datetime\n",
    "    from google.cloud import storage\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    sys.path.append('/usr/app/')\n",
    "    sys.path.append('/usr/app/src')\n",
    "    import src.utils as utils\n",
    "    import src.pipeline_modules as pipeline_modules\n",
    "    from src.guara.modeling.supervised_modelz import SupervisedModelz\n",
    "    \n",
    "    Xtrain = pd.read_parquet(Xtrain_.path + \".parquet\")\n",
    "    Xval = pd.read_parquet(Xval_.path + \".parquet\")\n",
    "    ytrain = pd.read_parquet(ytrain_.path + \".parquet\")\n",
    "    yval = pd.read_parquet(yval_.path + \".parquet\")\n",
    "    \n",
    "    dtrain = xgb.DMatrix(Xtrain, ytrain)\n",
    "    dval = xgb.DMatrix(Xval, yval)\n",
    "    \n",
    "    scale_pos_weight=ytrain.value_counts(normalize=True)[0]/ytrain.value_counts(normalize=True)[1]  \n",
    "    \n",
    "    params = {\n",
    "        'gamma': 1, \n",
    "        'verbosity': 0, \n",
    "        'scale_pos_weight': 1.0, \n",
    "        'eta': 0.32924394564404313, \n",
    "        'colsample_bytree': 0.6997715470767337, \n",
    "        'num_iterations': 259.98061008076706, \n",
    "        'lambda': 9.840799645070883, \n",
    "        'n_estimators': 372, \n",
    "        'max_depth': 5, \n",
    "        'feature_fraction': 0,\n",
    "        'scale_pos_weight': scale_pos_weight,\n",
    "        'eval_set': dval\n",
    "    }\n",
    "\n",
    "    bst = xgb.train(params, dtrain, 20)\n",
    "    model_.metadata['framework'] = 'xgb'\n",
    "    model = model_.path + '.bst'\n",
    "    bst.save_model(model)\n",
    "    \n",
    "    storage_client = storage.Client()\n",
    "    bucket_name='gpa-churn'\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    model_file='artifacts/training_pipeline/xgb/model.bst'\n",
    "    blob = bucket.blob(model_file)\n",
    "    bst.save_model('model.bst')\n",
    "    blob.upload_from_filename('model.bst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5542cd17-b4c8-4d35-b0c4-ac5471398ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    #packages_to_install=['pandas', 'numpy'],\n",
    "    base_image=\"gcr.io/gpa-poc-001/churn-base-image-src-xgb@sha256:61db16ec13bba7d8023fff61329c6c28a7eb119f8f837fce4c09258776c16727\",\n",
    "    output_component_file=\"sim_deploy.yaml\"\n",
    ")\n",
    "\n",
    "def deploy_endpoint(\n",
    "    model_: Input[Model],\n",
    "    vertex_endpoint: Output[Artifact],\n",
    "    vertex_model: Output[Model]\n",
    "    ):\n",
    "    \n",
    "    import os\n",
    "    import gc\n",
    "    import sys\n",
    "    import joblib\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import xgboost as xgb\n",
    "    from datetime import datetime\n",
    "    from google.cloud import storage\n",
    "    from google.cloud import aiplatform\n",
    "    \n",
    "    PROJECT_ID='gpa-poc-001'\n",
    "    ENDPOINT_NAME = 'churn-endpoint-simplepipe'\n",
    "    REGION=\"us-central1\"\n",
    "    DISPLAY_NAME = 'churn-model-simplepipe'\n",
    "    MODEL_NAME = 'churn-xgb-simplepipe'\n",
    "    CONTAINER_URI = \"us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-5:latest\"\n",
    "    ARTIFACT_URI = 'gs://gpa-churn/artifacts/training_pipeline/xgb/'\n",
    "    \n",
    "    endpoints = aiplatform.Endpoint.list(\n",
    "        filter='display_name=\"{}\"'.format(ENDPOINT_NAME),\n",
    "        order_by='create_time desc',\n",
    "        project=PROJECT_ID, \n",
    "        location=REGION,\n",
    "        )\n",
    "\n",
    "    if len(endpoints) > 0:\n",
    "        endpoint = endpoints[0]  # most recently created\n",
    "    else:\n",
    "        endpoint = aiplatform.Endpoint.create(\n",
    "        display_name=ENDPOINT_NAME, project=PROJECT_ID, location=REGION\n",
    "    )\n",
    "    \n",
    "    #Import a model programmatically\n",
    "    model_upload = aiplatform.Model.upload(\n",
    "        display_name = DISPLAY_NAME, \n",
    "        artifact_uri = ARTIFACT_URI,\n",
    "        serving_container_image_uri =  CONTAINER_URI,\n",
    "        serving_container_health_route=f\"/v1/models/{MODEL_NAME}\",\n",
    "        serving_container_predict_route=f\"/v1/models/{MODEL_NAME}:predict\",\n",
    "        serving_container_environment_variables={\n",
    "        \"MODEL_NAME\": MODEL_NAME,\n",
    "    },       \n",
    "    )\n",
    "    \n",
    "    model_deploy = model_upload.deploy(\n",
    "        machine_type=\"n1-standard-4\", \n",
    "        endpoint=endpoint,\n",
    "        traffic_split={\"0\": 100},\n",
    "        deployed_model_display_name=DISPLAY_NAME,\n",
    "    )\n",
    "\n",
    "    # Save data to the output params\n",
    "    vertex_model.uri = model_deploy.resource_name "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798f22fc-90a6-418b-9c24-dfc8e0faff2e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f4070a0-e504-4246-8467-b60591c95ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the pipeline\n",
    "from datetime import datetime\n",
    "TIMESTAMP =datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "DISPLAY_NAME = 'pipeline-test-{}'.format(TIMESTAMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f6b93de-8664-4a23-a12a-1d25c1b92671",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    name=\"pipeline-train-churn\")\n",
    "\n",
    "def pipeline(\n",
    "    project: str = 'gpa-poc-001',\n",
    "    region: str = \"southamerica-east1\", \n",
    "    serving_container_image_uri: str = \"gcr.io/gpa-poc-001/churn-base-image-src-xgb@sha256:61db16ec13bba7d8023fff61329c6c28a7eb119f8f837fce4c09258776c16727\"\n",
    "    ):\n",
    "    \n",
    "    data_op = get_preprocessed_data(\n",
    "        prefix='gs://gpa-churn/data/processed/input/'\n",
    "        )\n",
    "    \n",
    "    train_model_op = train_model(\n",
    "        data_op.outputs['Xtrain_'],\n",
    "        data_op.outputs['Xval_'],\n",
    "        data_op.outputs['ytrain_'],\n",
    "        data_op.outputs['yval_']\n",
    "        )\n",
    "           \n",
    "    deploy_model_op = deploy_endpoint(\n",
    "        train_model_op.outputs['model_']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91545e9d-ca9a-4fe1-be79-f7f717dff4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1281: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "compiler.Compiler().compile(pipeline_func=pipeline,\n",
    "        package_path='ml_pipeline_test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a47ca6-608a-488e-80a3-30a94dba0b41",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fab0af9f-45d8-4376-9ac0-a3dbbee75940",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_pipeline = pipeline_jobs.PipelineJob(\n",
    "    display_name=\"churn-test-pipeline\",\n",
    "    template_path=\"ml_pipeline_test.json\",\n",
    "    enable_caching=True,\n",
    "    location=REGION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "150ab38b-1ea0-4c91-bb5a-e75d314053c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/437364709834/locations/southamerica-east1/pipelineJobs/pipeline-train-churn-20220603015119\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/437364709834/locations/southamerica-east1/pipelineJobs/pipeline-train-churn-20220603015119')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/southamerica-east1/pipelines/runs/pipeline-train-churn-20220603015119?project=437364709834\n",
      "PipelineJob projects/437364709834/locations/southamerica-east1/pipelineJobs/pipeline-train-churn-20220603015119 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/437364709834/locations/southamerica-east1/pipelineJobs/pipeline-train-churn-20220603015119 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/437364709834/locations/southamerica-east1/pipelineJobs/pipeline-train-churn-20220603015119 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/437364709834/locations/southamerica-east1/pipelineJobs/pipeline-train-churn-20220603015119 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/437364709834/locations/southamerica-east1/pipelineJobs/pipeline-train-churn-20220603015119 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/437364709834/locations/southamerica-east1/pipelineJobs/pipeline-train-churn-20220603015119 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/437364709834/locations/southamerica-east1/pipelineJobs/pipeline-train-churn-20220603015119\n"
     ]
    }
   ],
   "source": [
    "start_pipeline.run()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
